<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />

<meta name="viewport" content="width=device-width, initial-scale=1" />



<title>Model description for glca</title>

<script src="data:application/javascript;base64,Ly8gUGFuZG9jIDIuOSBhZGRzIGF0dHJpYnV0ZXMgb24gYm90aCBoZWFkZXIgYW5kIGRpdi4gV2UgcmVtb3ZlIHRoZSBmb3JtZXIgKHRvCi8vIGJlIGNvbXBhdGlibGUgd2l0aCB0aGUgYmVoYXZpb3Igb2YgUGFuZG9jIDwgMi44KS4KZG9jdW1lbnQuYWRkRXZlbnRMaXN0ZW5lcignRE9NQ29udGVudExvYWRlZCcsIGZ1bmN0aW9uKGUpIHsKICB2YXIgaHMgPSBkb2N1bWVudC5xdWVyeVNlbGVjdG9yQWxsKCJkaXYuc2VjdGlvbltjbGFzcyo9J2xldmVsJ10gPiA6Zmlyc3QtY2hpbGQiKTsKICB2YXIgaSwgaCwgYTsKICBmb3IgKGkgPSAwOyBpIDwgaHMubGVuZ3RoOyBpKyspIHsKICAgIGggPSBoc1tpXTsKICAgIGlmICghL15oWzEtNl0kL2kudGVzdChoLnRhZ05hbWUpKSBjb250aW51ZTsgIC8vIGl0IHNob3VsZCBiZSBhIGhlYWRlciBoMS1oNgogICAgYSA9IGguYXR0cmlidXRlczsKICAgIHdoaWxlIChhLmxlbmd0aCA+IDApIGgucmVtb3ZlQXR0cmlidXRlKGFbMF0ubmFtZSk7CiAgfQp9KTsK"></script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>






<link rel="stylesheet" href="data:text/css,body%20%7B%0Abackground%2Dcolor%3A%20%23fff%3B%0Amargin%3A%201em%20auto%3B%0Amax%2Dwidth%3A%20700px%3B%0Aoverflow%3A%20visible%3B%0Apadding%2Dleft%3A%202em%3B%0Apadding%2Dright%3A%202em%3B%0Afont%2Dfamily%3A%20%22Open%20Sans%22%2C%20%22Helvetica%20Neue%22%2C%20Helvetica%2C%20Arial%2C%20sans%2Dserif%3B%0Afont%2Dsize%3A%2014px%3B%0Aline%2Dheight%3A%201%2E35%3B%0A%7D%0A%23TOC%20%7B%0Aclear%3A%20both%3B%0Amargin%3A%200%200%2010px%2010px%3B%0Apadding%3A%204px%3B%0Awidth%3A%20400px%3B%0Aborder%3A%201px%20solid%20%23CCCCCC%3B%0Aborder%2Dradius%3A%205px%3B%0Abackground%2Dcolor%3A%20%23f6f6f6%3B%0Afont%2Dsize%3A%2013px%3B%0Aline%2Dheight%3A%201%2E3%3B%0A%7D%0A%23TOC%20%2Etoctitle%20%7B%0Afont%2Dweight%3A%20bold%3B%0Afont%2Dsize%3A%2015px%3B%0Amargin%2Dleft%3A%205px%3B%0A%7D%0A%23TOC%20ul%20%7B%0Apadding%2Dleft%3A%2040px%3B%0Amargin%2Dleft%3A%20%2D1%2E5em%3B%0Amargin%2Dtop%3A%205px%3B%0Amargin%2Dbottom%3A%205px%3B%0A%7D%0A%23TOC%20ul%20ul%20%7B%0Amargin%2Dleft%3A%20%2D2em%3B%0A%7D%0A%23TOC%20li%20%7B%0Aline%2Dheight%3A%2016px%3B%0A%7D%0Atable%20%7B%0Amargin%3A%201em%20auto%3B%0Aborder%2Dwidth%3A%201px%3B%0Aborder%2Dcolor%3A%20%23DDDDDD%3B%0Aborder%2Dstyle%3A%20outset%3B%0Aborder%2Dcollapse%3A%20collapse%3B%0A%7D%0Atable%20th%20%7B%0Aborder%2Dwidth%3A%202px%3B%0Apadding%3A%205px%3B%0Aborder%2Dstyle%3A%20inset%3B%0A%7D%0Atable%20td%20%7B%0Aborder%2Dwidth%3A%201px%3B%0Aborder%2Dstyle%3A%20inset%3B%0Aline%2Dheight%3A%2018px%3B%0Apadding%3A%205px%205px%3B%0A%7D%0Atable%2C%20table%20th%2C%20table%20td%20%7B%0Aborder%2Dleft%2Dstyle%3A%20none%3B%0Aborder%2Dright%2Dstyle%3A%20none%3B%0A%7D%0Atable%20thead%2C%20table%20tr%2Eeven%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0A%7D%0Ap%20%7B%0Amargin%3A%200%2E5em%200%3B%0A%7D%0Ablockquote%20%7B%0Abackground%2Dcolor%3A%20%23f6f6f6%3B%0Apadding%3A%200%2E25em%200%2E75em%3B%0A%7D%0Ahr%20%7B%0Aborder%2Dstyle%3A%20solid%3B%0Aborder%3A%20none%3B%0Aborder%2Dtop%3A%201px%20solid%20%23777%3B%0Amargin%3A%2028px%200%3B%0A%7D%0Adl%20%7B%0Amargin%2Dleft%3A%200%3B%0A%7D%0Adl%20dd%20%7B%0Amargin%2Dbottom%3A%2013px%3B%0Amargin%2Dleft%3A%2013px%3B%0A%7D%0Adl%20dt%20%7B%0Afont%2Dweight%3A%20bold%3B%0A%7D%0Aul%20%7B%0Amargin%2Dtop%3A%200%3B%0A%7D%0Aul%20li%20%7B%0Alist%2Dstyle%3A%20circle%20outside%3B%0A%7D%0Aul%20ul%20%7B%0Amargin%2Dbottom%3A%200%3B%0A%7D%0Apre%2C%20code%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0Aborder%2Dradius%3A%203px%3B%0Acolor%3A%20%23333%3B%0Awhite%2Dspace%3A%20pre%2Dwrap%3B%20%0A%7D%0Apre%20%7B%0Aborder%2Dradius%3A%203px%3B%0Amargin%3A%205px%200px%2010px%200px%3B%0Apadding%3A%2010px%3B%0A%7D%0Apre%3Anot%28%5Bclass%5D%29%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0A%7D%0Acode%20%7B%0Afont%2Dfamily%3A%20Consolas%2C%20Monaco%2C%20%27Courier%20New%27%2C%20monospace%3B%0Afont%2Dsize%3A%2085%25%3B%0A%7D%0Ap%20%3E%20code%2C%20li%20%3E%20code%20%7B%0Apadding%3A%202px%200px%3B%0A%7D%0Adiv%2Efigure%20%7B%0Atext%2Dalign%3A%20center%3B%0A%7D%0Aimg%20%7B%0Abackground%2Dcolor%3A%20%23FFFFFF%3B%0Apadding%3A%202px%3B%0Aborder%3A%201px%20solid%20%23DDDDDD%3B%0Aborder%2Dradius%3A%203px%3B%0Aborder%3A%201px%20solid%20%23CCCCCC%3B%0Amargin%3A%200%205px%3B%0A%7D%0Ah1%20%7B%0Amargin%2Dtop%3A%200%3B%0Afont%2Dsize%3A%2035px%3B%0Aline%2Dheight%3A%2040px%3B%0A%7D%0Ah2%20%7B%0Aborder%2Dbottom%3A%204px%20solid%20%23f7f7f7%3B%0Apadding%2Dtop%3A%2010px%3B%0Apadding%2Dbottom%3A%202px%3B%0Afont%2Dsize%3A%20145%25%3B%0A%7D%0Ah3%20%7B%0Aborder%2Dbottom%3A%202px%20solid%20%23f7f7f7%3B%0Apadding%2Dtop%3A%2010px%3B%0Afont%2Dsize%3A%20120%25%3B%0A%7D%0Ah4%20%7B%0Aborder%2Dbottom%3A%201px%20solid%20%23f7f7f7%3B%0Amargin%2Dleft%3A%208px%3B%0Afont%2Dsize%3A%20105%25%3B%0A%7D%0Ah5%2C%20h6%20%7B%0Aborder%2Dbottom%3A%201px%20solid%20%23ccc%3B%0Afont%2Dsize%3A%20105%25%3B%0A%7D%0Aa%20%7B%0Acolor%3A%20%230033dd%3B%0Atext%2Ddecoration%3A%20none%3B%0A%7D%0Aa%3Ahover%20%7B%0Acolor%3A%20%236666ff%3B%20%7D%0Aa%3Avisited%20%7B%0Acolor%3A%20%23800080%3B%20%7D%0Aa%3Avisited%3Ahover%20%7B%0Acolor%3A%20%23BB00BB%3B%20%7D%0Aa%5Bhref%5E%3D%22http%3A%22%5D%20%7B%0Atext%2Ddecoration%3A%20underline%3B%20%7D%0Aa%5Bhref%5E%3D%22https%3A%22%5D%20%7B%0Atext%2Ddecoration%3A%20underline%3B%20%7D%0A%0Acode%20%3E%20span%2Ekw%20%7B%20color%3A%20%23555%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%0Acode%20%3E%20span%2Edt%20%7B%20color%3A%20%23902000%3B%20%7D%20%0Acode%20%3E%20span%2Edv%20%7B%20color%3A%20%2340a070%3B%20%7D%20%0Acode%20%3E%20span%2Ebn%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Efl%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Ech%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Est%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Eco%20%7B%20color%3A%20%23888888%3B%20font%2Dstyle%3A%20italic%3B%20%7D%20%0Acode%20%3E%20span%2Eot%20%7B%20color%3A%20%23007020%3B%20%7D%20%0Acode%20%3E%20span%2Eal%20%7B%20color%3A%20%23ff0000%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%0Acode%20%3E%20span%2Efu%20%7B%20color%3A%20%23900%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%0Acode%20%3E%20span%2Eer%20%7B%20color%3A%20%23a61717%3B%20background%2Dcolor%3A%20%23e3d2d2%3B%20%7D%20%0A" type="text/css" />




</head>

<body>




<h1 class="title toc-ignore">Model description for glca</h1>



<p>Suppose that there are <span class="math inline">\(G\)</span> groups, and the <span class="math inline">\(g\)</span>th group consists of <span class="math inline">\(n_g\)</span> observations for <span class="math inline">\(g=1,\ldots,G\)</span>, and there are <span class="math inline">\(M\)</span> categorical manifest items, where the <span class="math inline">\(m\)</span>th item has <span class="math inline">\(r_m\)</span> categories for <span class="math inline">\(m=1,\ldots,M\)</span>. Let <span class="math inline">\(\mathbf{Y}_{ig}=(Y_{ig1}, \dots, Y_{igM})^\top\)</span> and <span class="math inline">\({\bf y}_{ig} = (y_{ig1}, \ldots, y_{igM})^\top\)</span> denote a set of item variables and their responses given by the <span class="math inline">\(i\)</span>th individual within the <span class="math inline">\(g\)</span>th group, respectively. The number of possible response patterns of <span class="math inline">\(\mathbf{Y}_{ig}\)</span> is <span class="math inline">\(\prod_{m = 1}^{M}r_m\)</span>, and it is likely that most of these response patterns are sparse. The multiple-group LCA assumes that associations among manifest items can be explained by the latent classifier <span class="math inline">\(L_{ig}\)</span>, where <span class="math inline">\(L_{ig}\)</span> is the latent class variable having <span class="math inline">\(C\)</span> categories for the <span class="math inline">\(i\)</span>th individual within the <span class="math inline">\(g\)</span>th group. To reflect multiple-group data structures, we discuss two different LCA approaches, namely fixed-effect and random-effect LCA.</p>
<div id="fixed-effect-latent-class-analysis" class="section level2">
<h2>Fixed-effect latent class analysis</h2>
<p>The fixed-effect LCA can reflect group differences in latent structure by specifying an LCR model for a given subgroup. We extend the simultaneous LCA  by incorporating logistic regression in the class prevalence and refer it to <em>multiple-group latent class regression</em> (mgLCR). Let <span class="math inline">\({\bf x}_{ig}=(x_{ig1}, \ldots, x_{igp})^\top\)</span> be a subject-specific <span class="math inline">\(p\times 1\)</span> vector of covariates for the <span class="math inline">\(i\)</span>th individual within the <span class="math inline">\(g\)</span>th group, either discrete or continuous. Then, the observed-data likelihood of mgLCR for the <span class="math inline">\(i\)</span>th individual within the <span class="math inline">\(g\)</span>th group can be specified as</p>
<p><span class="math display">\[\begin{eqnarray}
\label{eq:likeli}
\mathcal{L}_{ig} &amp;=&amp; \sum_{c=1}^C P(\mathbf{Y}_{ig} = \mathbf{y}_{ig}, L_{ig} = c \mid {\bf x}_{ig}) \nonumber \\
&amp;=&amp; \sum_{c=1}^C \left[ P(L_{ig} = c \mid {\bf x}_{ig}) \prod_{m = 1}^{M} P(y_{igm} = k \mid L_{ig} = c) \right] \nonumber  \\ 
&amp;=&amp; \sum_{c=1}^C \left[ \gamma_{c \mid g}({\bf x}_{ig}) \prod_{m = 1}^{M}\prod_{k = 1}^{r_m} \rho_{mk \mid cg}^{I(y_{igm} = k)} \right], 
\end{eqnarray}\]</span></p>
<p>where <span class="math inline">\(I(y_{igm}=k)\)</span> is an indicator function that is equal to 1 when the response to the <span class="math inline">\(m\)</span>th item from the <span class="math inline">\(i\)</span>th individual within the <span class="math inline">\(g\)</span>th group is <span class="math inline">\(k\)</span> and is otherwise equal to 0. The likelihood given in  contains two types of parameters:</p>
<p>The <span class="math inline">\(\rho\)</span>-parameter is the measurement parameter in mgLCR (i.e., item-response probability), describing a tendency of individuals in a latent class <span class="math inline">\(c\)</span> to respond to the <span class="math inline">\(m\)</span>th item for <span class="math inline">\(m = 1,\ldots,M\)</span>. Comparison of estimated item-response probabilities across groups is a valuable strategy for quantifying measurement invariance because they solely determine the meaning of the latent class. By comparing the model fit with the parameter held constant across groups (i.e., <span class="math inline">\(\rho_{mk \mid c} = \rho_{mk \mid c1} = \dots = \rho_{mk \mid cG}\)</span> for <span class="math inline">\(k=1,\ldots,r_m\)</span>, <span class="math inline">\(m=1,\ldots,M\)</span>, and <span class="math inline">\(c=1,\ldots,C\)</span>) against an alternative model with freely varying parameters, we obtain evidence on whether measurement invariance across groups can be assumed. As given in , the subject-specific covariates <span class="math inline">\({\bf x}_{ig}\)</span> may influence the probability of the individual belonging to a specific class in the form of logistic regression as</p>
<p><span class="math display">\[\begin{eqnarray}
\label{mgLCA_reg}
\gamma_{c \mid g}(\mathbf{x}_{ig}) = P(L_{ig} = c \mid {\bf x}_{ig}) = \frac{\exp(\alpha_{c \mid g}+{\bf x}_{ig}^\top \boldsymbol{\beta}_{c \mid g})}{\sum_{c&#39;=1}^C\exp(\alpha_{c&#39; \mid g}+{\bf x}_{ig}^\top \boldsymbol{\beta}_{c&#39; \mid g})}, 
\end{eqnarray}\]</span></p>
<p>where the coefficient vector <span class="math inline">\(\boldsymbol{\beta}_{c \mid g} = (\beta_{1c \mid g}, \ldots, \beta_{pc \mid g})^\top\)</span> can be interpreted as the expected change in the log odds of belonging to a class <span class="math inline">\(c\)</span> versus belonging to the referent class <span class="math inline">\(C\)</span> (i.e., <span class="math inline">\(\alpha_{C \mid g}=0\)</span> and <span class="math inline">\(\boldsymbol{\beta}_{C \mid g} = {\bf 0}\)</span> for <span class="math inline">\(g=1, \ldots, G\)</span>). Then, the observed log-likelihood function for the mgLCR model can be specified as</p>
<p><span class="math display">\[\begin{eqnarray}
\label{loglik_mgLCA}
\ell_{mgLCR} = \sum_{g = 1}^{G}\sum_{i = 1}^{n_{g}} \log \mathcal{L}_{ig}.
\end{eqnarray}\]</span></p>
<p>It should be noted that, similar to item-response probabilities, coefficients of logistic regression can be constrained to be equal across subgroups (i.e., <span class="math inline">\(\boldsymbol{\beta}_{c} = \boldsymbol{\beta}_{c \mid 1}= \cdots = \boldsymbol{\beta}_{c \mid G}\)</span> for <span class="math inline">\(c=1, \ldots,C\)</span>) to test whether the effects of covariates are identical across groups.</p>
</div>
<div id="random-effect-latent-class-analysis" class="section level2">
<h2>Random-effect latent class analysis</h2>
<p>As in Section~, there are parametric and nonparametric approaches for random-effect LCA. The random-effect LCA considers the group variation in the latent class prevalence for each group using random coefficients, for example, For example, the prevalence of latent class for each group can be modeled using random coefficients <span class="math inline">\(\boldsymbol{\lambda}=(\lambda_1, \ldots, \lambda_G)^\top\)</span> as</p>
<p><span class="math display">\[
P(L_{ig} = c) = 
\frac{\exp(\alpha_{c} + \sigma_{c} \lambda_{g})}{\sum_{c&#39; = 1}^{C}\exp(\alpha_{c&#39;} + \sigma_{c&#39;} \lambda_{g})},
\]</span></p>
<p>where <span class="math inline">\(\boldsymbol{\lambda}=(\lambda_1, \ldots, \lambda_G)^\top\)</span> represents group variation in the class prevalence. For random-effect LCA, there are parametric and nonparametric approaches to random coefficients . In the parametric random-effect LCA, the random coefficients are assumed to be derived from parametric distributions such as standard normal distribution. However, the nonparametric approach assumes no specific distribution; rather, it only assumes that random coefficients follow a specific probability mass function with some mass points. In other words, the nonparametric approach employs categorical level-2 latent variable (i.e., latent cluster) <span class="math inline">\(U_{g}\)</span> whose probability mass function is <span class="math inline">\(P(U_g=w) = \delta_w\)</span> for <span class="math inline">\(w=1,\ldots,W\)</span>. Using the classification mechanics of LCA, the latent cluster membership of level-2 units can be identified by the small number of representative patterns of class prevalences in multiple groups. Therefore, the meaning of the <span class="math inline">\(w\)</span>th level of latent cluster variable is determined by the prevalence of latent classes <span class="math inline">\(P(L_{ig} = c \mid U_{g} = w)\)</span> for <span class="math inline">\(c=1,\ldots,C\)</span>. Considering latent cluster variable as a group variable, the nonparametric approach provides more meaningful interpretations in group comparison than parametric approach; we can examine whether the latent class structure differs across latent cluster memberships. Therefore, we focus on the nonparametric random-effect LCA, hereafter referred to as {} (npLCR).</p>
<p>In npLCR, the latent cluster variable is used to specify the prevalence of latent class as</p>
<p>_{ig(cw)} = <span class="math display">\[
P(L_{ig} = c \mid U_{g} = w) = 
\frac{\exp(\alpha_{c \mid w})}{\sum_{c&#39; = 1}^{C}\exp(\alpha_{c&#39; \mid w})},
\]</span> \end{eqnarray}</p>
<p>where the probability mass function for the random coefficient <span class="math inline">\(\alpha_{c \mid w}\)</span> is <span class="math inline">\(P(U_g=w) = \delta_w\)</span> for <span class="math inline">\(w=1,\ldots,W\)</span>, which can be interpreted as latent cluster prevalence.</p>
<p>The observed-data likelihood of npLCR for the <span class="math inline">\(g\)</span>th group can be expressed by</p>
<p><span class="math display">\[\begin{eqnarray}
\mathcal{L}_{g} &amp;=&amp;
\sum_{w = 1}^{W} P(U_g = w) \prod_{i=1}^{n_g} \left\{\sum_{c = 1}^{C} P(Y_{ig}=y_{ig}, L_{ig} = c \mid U_{g} = w, \mathbf{x}_{ig}, \mathbf{z}_{g})\label{grouploglik_mLCA}\right\} \nonumber \\
&amp;=&amp; \sum_{w = 1}^{W} P(U_g = w) \prod_{i=1}^{n_g} \left\{\sum_{c = 1}^{C} P(L_{ig} = c \mid U_{g} = w, \mathbf{x}_{ig}, \mathbf{z}_{g}) \prod_{m=1}^M P(Y_{igm}=k \mid L_{ig} = c )  \right\} \nonumber \\
&amp;=&amp; \sum_{w = 1}^{W} \delta_{w} \prod_{i=1}^{n_g}  \left\{ \sum_{c = 1}^{C} \gamma_{c \mid w}(\mathbf{x}_{ig}, \mathbf{z}_{g}) \prod_{m = 1}^{M}\prod_{k = 1}^{r_m}\rho_{mk \mid c}^{I(y_{igm} = k)}\right\},
\end{eqnarray}\]</span></p>
<p>where <span class="math inline">\({\bf x}_{ig} = (x_{ig1}, \ldots, x_{igp})^\top\)</span> and <span class="math inline">\({\bf z}_g=(z_{g1}, \ldots, z_{gq})^\top\)</span> denote vectors of subject-specific (i.e., level-1) and group-specific (i.e., level-2) covariates for <span class="math inline">\(i=1, \ldots, n_g\)</span> and <span class="math inline">\(g=1,\ldots,G\)</span>, respectively. where <span class="math inline">\(I(y_{igm}=k)\)</span> is an indicator function that is equal to 1 when the response to the <span class="math inline">\(m\)</span>th item from the <span class="math inline">\(i\)</span>th individual within the <span class="math inline">\(g\)</span>th group is <span class="math inline">\(k\)</span> and is otherwise equal to 0. The likelihood given in~ contains three types of parameters:</p>
<p>In npLCR we can incorporate level-1 and/or level-2 covariates to predict latent class membership. The class prevalence can be modeled using the logistic regression as</p>
<p><span class="math display">\[\begin{eqnarray}
\label{MLCA_reg}
\gamma_{c \mid w}(\mathbf{x}_{ig}, \mathbf{z}_{g}) = P(L_{ig} = c \mid U_{g} = w, \mathbf{x}_{ig}, \mathbf{z}_{g}) = 
\frac{\exp(\alpha_{c \mid w} + \mathbf{x}^{\top}_{ig}\boldsymbol{\beta}_{1c \mid w} + \mathbf{z}^{\top}_{g}\boldsymbol{\beta}_{2c})}
{\sum_{c&#39; = 1}^{C} \exp(\alpha_{c&#39; \mid w} + \mathbf{x}^{\top}_{ig}\boldsymbol{\beta}_{1c&#39; \mid w} + \mathbf{z}^{\top}_{g}\boldsymbol{\beta}_{2c&#39;})},
\end{eqnarray}\]</span></p>
<p>where vectors <span class="math inline">\(\boldsymbol{\beta}_{1c \mid w} = (\beta_{11c \mid w}, \ldots, \beta_{1pc \mid w})^\top\)</span> and <span class="math inline">\(\boldsymbol{\beta}_{2c} = (\beta_{21c}, \ldots, \beta_{2qc})^\top\)</span> are logistic regression coefficients for level-1 and level-2 covariates, respectively. Then, the observed log-likelihood of npLCR is specified as</p>
<p><span class="math display">\[\begin{eqnarray}
\label{loglik_mLCA}
\ell_{npLCR} = \sum_{g = 1}^{G} \log \mathcal{L}_{g}.
\end{eqnarray}\]</span></p>
<p>Note that coefficients for level-1 covariates depend on both latent classes and clusters, while coefficients for level-2 covariates depend only on latent class membership. We may refer the model () to the random slope model as coefficients for level-1 covariates are different across latent clusters. The coefficients for level-1 covariates can be constrained to be equal across clusters (i.e., <span class="math inline">\(\boldsymbol{\beta}_{1c} = \boldsymbol{\beta}_{1c \mid 1} = \cdots = \boldsymbol{\beta}_{1c \mid W}\)</span> for <span class="math inline">\(c=1, \ldots,C\)</span>) to test whether the effects of level-1 covariates are identical across all latent cluster memberships. It should also be noted that the measurement invariance is assumed across latent cluster memberships in npLCR (i.e., <span class="math inline">\(\rho_{mk \mid c} = \rho_{mk \mid c1} = \dots = \rho_{mk \mid cW}\)</span> for <span class="math inline">\(k=1,\ldots,r_m\)</span>, <span class="math inline">\(m=1,\ldots,M\)</span>, and <span class="math inline">\(c=1,\ldots,C\)</span>). If not, the item response probability may vary across latent cluster memberships, suggesting that the latent class structure itself is different between latent clusters. Thus, it no longer makes sense to use latent class prevalences as identifiers for the latent cluster membership. It should also be noted that we should assume measurement invariance across latent cluster memberships (i.e., <span class="math inline">\(\rho_{mk \mid c} = \rho_{mk \mid c1} = \dots = \rho_{mk \mid cW}\)</span> for <span class="math inline">\(k=1,\ldots,r_m\)</span>, <span class="math inline">\(m=1,\ldots,M\)</span>, and <span class="math inline">\(c=1,\ldots,C\)</span>) in npLCR because latent cluster membership is identified by latent class prevalences of each group. If item response probabilities vary across latent clusters, the meaning of latent classes varies from cluster to cluster. Then, it no longer makes sense to use latent class prevalences as identifiers for latent clusters.</p>
</div>
<div id="estimation-for-fixed-effect-latent-class-analysis" class="section level2">
<h2>Estimation for fixed-effect latent class analysis</h2>
<p>The package  finds the maximum-likelihood (ML) estimates for mgLCR and npLCR using expectation-maximization (EM) algorithm . The EM algorithm iterates two steps: expectation step (E-step) and maximization step (M-step) in order to find the solution maximizing the log-likelihood functions given in <span class="math inline">\(\eqref{loglik_mgLCA}\)</span> and <span class="math inline">\(\eqref{loglik_mLCA}\)</span>.</p>
<p>For mgLCR, E-step computes the posterior probabilities</p>
<p><span class="math display">\[\begin{eqnarray*}
\label{post}
  \theta_{ig(c)} = P(L_{ig} = c \mid \mathbf{Y}_{ig} = \mathbf{y}_{ig}, \mathbf{x}_{ig})
  = \frac{\gamma_{c \mid g}(\mathbf{x}_{ig}) \prod_{m = 1}^{M}\prod_{k = 1}^{r_m} \rho_{mk \mid cg}^{I(y_{igm} = k)}}{\sum_{c&#39; = 1}^{C} \gamma_{c&#39; \mid g}(\mathbf{x}_{ig}) \prod_{m = 1}^{M}\prod_{k = 1}^{r_m} \rho_{mk \mid c&#39;g}^{I(y_{igm} = k)}}\\
\end{eqnarray*}\]</span></p>
<p>with current estimates for <span class="math inline">\(i=1, \ldots, n_g\)</span>, <span class="math inline">\(g=1,\ldots,G\)</span>, and <span class="math inline">\(c=1,\ldots,C\)</span>. M-step maximizes the complete-data likelihood (i.e., the likelihood for the cross-classification by <span class="math inline">\(L_{ig}\)</span> and <span class="math inline">\(\mathbf{y}_{ig}\)</span>) with respect to <span class="math inline">\(\beta\)</span>- and <span class="math inline">\(\rho\)</span>-parameters. In particular, when all values of <span class="math inline">\(\theta_{ig(c)}\)</span> are known, updated estimates for <span class="math inline">\(\beta\)</span>-parameters can be calculated by the standard Newton-Raphson algorithm for multinomial logistic regression given in , provided that the computational routine allows fractional responses rather than integer counts~. Therefore, the package  conducts one-cycle of Newton-Raphson algorithm to update <span class="math inline">\(\beta\)</span>-parameters at every iteration in M-step. If there is no covariate in the model, the class prevalence can be updated directly without estimating <span class="math inline">\(\beta\)</span>-parameters as <span class="math inline">\(\hat{\gamma}_{c \mid g} = P(L_{ig}=c) = \sum_{i=1}^{n_g} \theta_{ig(c)}/n_g\)</span> for <span class="math inline">\(c=1,\ldots,C\)</span> and <span class="math inline">\(g=1,\ldots,G\)</span>. The item-response probabilities, <span class="math inline">\(\rho_{mk \mid cg}\)</span> can be interpreted as parameters in a multinomial distribution when <span class="math inline">\(\theta_{ig(c)}\)</span> is known, so we have</p>
<p><span class="math display">\[
\hat{\rho}_{mk \mid cg} = \frac{\sum_{i=1}^{n_g} \theta_{ig(c)}I(y_{igm} = k)}{\sum_{i=1}^{n_g}  \theta_{ig(c)}}
\]</span></p>
<p>for <span class="math inline">\(k=1, \ldots, r_m\)</span>, <span class="math inline">\(m=1,\ldots,M\)</span>, <span class="math inline">\(c=1,\ldots,C\)</span>, and <span class="math inline">\(g=1,\ldots,G\)</span>. Under the measurement invariance assumption (i.e., <span class="math inline">\(\rho_{mk \mid c} = \rho_{mk \mid c1} = \dots = \rho_{mk \mid cG}\)</span>), the <span class="math inline">\(\rho\)</span>-parameter will be updated as</p>
<p><span class="math display">\[
\hat{\rho}_{mk \mid c} = \frac{\sum_{g = 1}^{G} \sum_{i = 1}^{n_g} \theta_{ig(c)}I(y_{igm} = k)}{\sum_{g = 1}^{G} \sum_{i = 1}^{n_g} \theta_{ig(c)}}
\]</span></p>
<p>for <span class="math inline">\(k=1, \ldots, r_m\)</span>, <span class="math inline">\(m=1,\ldots,M\)</span>, and <span class="math inline">\(c=1,\ldots,C\)</span>.</p>
</div>
<div id="estimation-for-random-effect-latent-class-analysis" class="section level2">
<h2>Estimation for random-effect latent class analysis</h2>
<p>For npLCR, E-step involves the joint posterior probability</p>
<p><span class="math display">\[\begin{eqnarray}
\label{full_post}
\theta_{g(w, c_1, \ldots, c_{n_g})} =  P(U_g = w, L_{1g}=c_{1},  \ldots, L_{n_gg}=c_{n_g} \mid \mathbf{Y}_g = \mathbf{y}_g, \mathbf{x}_g, \mathbf{z}_g),
\end{eqnarray}\]</span></p>
<p>where <span class="math inline">\(\mathbf{y}_g = (\mathbf{y}_{1g}^\top, \ldots, \mathbf{y}_{n_gg}^\top)^\top\)</span> and <span class="math inline">\(\mathbf{x}_g = (\mathbf{x}_{1g}^\top, \ldots, \mathbf{x}_{n_gg}^\top)^\top\)</span> are all observations for <span class="math inline">\(M\)</span> manifest items and <span class="math inline">\(p\)</span> subject-specific covariates from the <span class="math inline">\(g\)</span>th group, respectively. As shown in~, computational complexity increases exponentially as the number of individuals per group <span class="math inline">\(n_g\)</span> increases in E-step for npLCR;  when the model has <span class="math inline">\(W\)</span> latent clusters and <span class="math inline">\(C\)</span> latent classes, the standard implementation of the E-step would yield dimensional complexity proportional to <span class="math inline">\(W \times C^{n_g}\)</span> for each group. It is not computationally feasible even with a moderate number of individuals per group. Besides, M-step for npLCR requires only some marginal versions of posterior probabilities rather than the joint posterior probability given in~. Therefore, the E-step can be modified to alleviate the computational complexity by accommodating the hierarchical structure of npLCR.  proposed the upward-downward (UD) algorithm for calculating the marginal posterior probability directly in the E-step. The UD algorithm is similar to the forward-backward (FB) algorithm for handling hidden Markov models . In the UD algorithm, marginal posterior probabilities <span class="math inline">\(\theta_{ig(w,c)}\)</span> can be calculated as</p>
<p><span class="math display">\[\begin{eqnarray}
\label{UD} 
\theta_{ig(w,c)} &amp;=&amp; P(U_g = w, L_{ig} = c \mid \mathbf{Y}_g=\mathbf{y}_g, \mathbf{x}_g, \mathbf{z}_g) \nonumber \\
&amp;=&amp; P(U_g = w \mid \mathbf{Y}_g=\mathbf{y}_g, \mathbf{x}_g, \mathbf{z}_g) P(L_{ig} = c \mid U_g = w, \mathbf{Y}_{ig}=\mathbf{y}_{ig}, \mathbf{x}_{ig}, \mathbf{z}_g) \nonumber \\
&amp;=&amp; \theta_{g(w)} \theta_{ig(c \mid w)} 
\end{eqnarray}\]</span></p>
<p>for <span class="math inline">\(i=1, \ldots, n_g\)</span>, <span class="math inline">\(g=1,\ldots,G\)</span>, <span class="math inline">\(c=1,\ldots,C\)</span>, and <span class="math inline">\(w=1,\ldots,W\)</span>. The marginal posterior probability, <span class="math inline">\(\theta_{ig(w,c)}\)</span> is the product of {}, <span class="math inline">\(\theta_{g(w)}\)</span> and {}, <span class="math inline">\(\theta_{ig(c \mid w)}\)</span>. In~, it should be noted that an individual’s class membership is assumed to depend only on his/her observations, which can be presented as <span class="math inline">\(P(L_{ig} = c \mid U_g = w, \mathbf{Y}_{g}=\mathbf{y}_{g}, \mathbf{x}_g, \mathbf{z}_g) = P(L_{ig} = c \mid U_g = w, \mathbf{Y}_{ig}=\mathbf{y}_{ig}, \mathbf{x}_{ig}, \mathbf{z}_g)\)</span> for <span class="math inline">\(i=1,\ldots,n_g\)</span>. Then, the upward and downward probabilities are easily calculated as</p>
<p><span class="math display">\[\begin{eqnarray*}
\theta_{g(w)} 
&amp;=&amp; \frac{\delta_{w} \prod_{i = 1}^{n_g} \left\{ \sum_{c = 1}^{C} \gamma_{c \mid w}(\mathbf{x}_{ig}, \mathbf{z}_g) \prod_{m = 1}^{M}\prod_{k = 1}^{r_m}\rho_{mk \mid c}^{I(y_{igm} = k)}\right\}  }
{\sum_{w = 1}^{W} \delta_{w} \prod_{i = 1}^{n_g} \left\{ \sum_{c = 1}^{C} \gamma_{c \mid w}(\mathbf{x}_{ig}, \mathbf{z}_g) \prod_{m = 1}^{M}\prod_{k = 1}^{r_m}\rho_{mk \mid c}^{I(y_{igm} = k)}\right\}}\;\; \mbox{and} \\
\theta_{ig(c \mid w)}
  &amp;=&amp; \frac{\gamma_{c \mid w}(\mathbf{x}_{ig}, \mathbf{z}_g) \prod_{m = 1}^{M}\prod_{k = 1}^{r_m}\rho_{mk \mid c}^{I(y_{igm} = k)}}
  {\sum_{c&#39; = 1}^C\gamma_{c&#39; \mid w}(\mathbf{x}_{ig}, \mathbf{z}_g) \prod_{m = 1}^{M}\prod_{k = 1}^{r_m}\rho_{mk \mid c&#39;}^{I(y_{igm} = k)}}
\end{eqnarray*}\]</span></p>
<p>with current estimates, respectively. The downward probability can be obtained as</p>
<p><span class="math display">\[\begin{eqnarray*}
\theta_{iwg(c)} &amp;=&amp;
  \frac{P(L_{ig} = c, \mathbf{Y}_{ig} = \mathbf{y}_{ig} \mid U_g = w, \mathbf{x}_{ig}, \mathbf{z}_g)}
  {\sum_{c&#39; = 1}^{C}P(L_{ig} = c&#39;, \mathbf{Y}_{ig} = \mathbf{y}_{ig} \mid U_g = w, \mathbf{x}_{ig}, \mathbf{z}_g)}\nonumber \\
  &amp;=&amp; \frac{\gamma_{c \mid w}(\mathbf{x}_{ig}, \mathbf{z}_g) \prod_{m = 1}^{M}\prod_{k = 1}^{r_m}\rho_{mk \mid c}^{I(y_{igm} = k)}}
  {\sum_{c&#39; = 1}^{K}\gamma_{c&#39; \mid w}(\mathbf{x}_{ig}, \mathbf{z}_g) \prod_{m = 1}^{M}\prod_{k = 1}^{r_m}\rho_{mk \mid c&#39;}^{I(y_{igm} = k)}}
\end{eqnarray*}\]</span></p>
<p>with current estimates. M-step maximizes the complete-data likelihood (i.e., the likelihood for the cross-classification by <span class="math inline">\(U_g\)</span>, <span class="math inline">\(L_{ig}\)</span> and <span class="math inline">\(\mathbf{y}_{ig}\)</span>) with respect to <span class="math inline">\(\boldsymbol{\beta}_{1c \mid w}\)</span>, <span class="math inline">\(\boldsymbol{\beta}_{2c}\)</span>, and <span class="math inline">\(\rho_{mk \mid c}\)</span>. In particular, when <span class="math inline">\(\theta_{ig(w,c)}\)</span> is known, updated estimates for <span class="math inline">\(\beta\)</span>-parameters can be calculated by standard Newton-Raphson algorithm for multinomial logistic regression given in , provided that the computational routine allows fractional responses rather than integer counts~. Therefore, the package  conducts one-cycle of Newton-Raphson algorithm to update <span class="math inline">\(\beta\)</span>-parameters at every iteration in M-step. If there is no covariate in the model, the class prevalence can be updated directly without estimating <span class="math inline">\(\beta\)</span>-parameters as <span class="math inline">\(\hat{\gamma}_{c \mid w} = P(L_{ig}=c \mid U_g =w) = \sum_{g=1}^G \sum_{i=1}^{n_g} \theta_{ig(w,c)}/\sum_{g=1}^G \theta_{g(w)}\)</span> for <span class="math inline">\(c=1,\ldots,C\)</span> and <span class="math inline">\(w=1,\ldots, W\)</span>. The cluster prevalence <span class="math inline">\(\delta_w\)</span> and the item-response probabilities <span class="math inline">\(\rho_{mk \mid c}\)</span> can be interpreted as parameters in multinomial distributions, so we have</p>
<p><span class="math display">\[\begin{eqnarray}
\hat{\delta}_{w} = \frac{\sum_{g = 1}^{G} \theta_{g(w)}}{G}
\;\; \text{and}
\;\; \hat{\rho}_{mk \mid c} = \frac{\sum_{g = 1}^{G} \sum_{i = 1}^{n_g} \theta_{ig(c)}I(y_{igm} = k)}{\sum_{g = 1}^{G} \sum_{i = 1}^{n_g} \theta_{ig(c)}} \label{m-nplcr}
\end{eqnarray}\]</span></p>
<p>for <span class="math inline">\(w=1,\ldots,W\)</span>, <span class="math inline">\(c=1,\ldots,C\)</span>, <span class="math inline">\(k=1,\ldots,r_m\)</span>, and <span class="math inline">\(m=1,\ldots,M\)</span>. The marginal posterior probability used in~ are easily obtained by <span class="math inline">\(\theta_{ig(c)} = \sum_{w = 1}^{W} \theta_{ig(w,c)}\)</span>.</p>
</div>
<div id="handling-missing-data" class="section level2">
<h2>Handling missing data</h2>
<p></p>
<p>Missing data occur in nearly all empirical data, despite the vigorous efforts of researchers to prevent it. Missing data cause two general problems. First, if subjects with any missing data on the variables are removed from the dataset, the sample can be very small especially when the number of missing values is large. This can lead to a great loss of information and poor statistical power. Second, frequently the subjects who provide incomplete data are different from those who provide complete data. If adjustments are not made for these differences, results may be biased.</p>
<p>In the case of random missing-data mechanisms (i.e., ignorable missing data) such as missing completely at random (MCAR) and missing at random (MAR) , two methods for dealing with missing data are typically available: full-information maximum likelihood (FIML) and multiple imputation (MI, ). In MI plausible values are imputed multiple times in place of missing values to create multiple complete datasets. The use of MI for multiple-group LCA has an advantage in that missing data on covariates and group variable can be handled. However, the disadvantage is that LCA must be fitted separately for each imputed complete dataset, and the results must be combined to obtain the final estimates. An important advantage of using MI for multiple-group LCA is that missing data on covariates and grouping variable can be handled. However, the disadvantage is that LCA must be fitted within each imputed complete dataset, and the results must be combined to obtain final estimates. FIML is a model-based missing data procedure where model estimates are adjusted on the basis of all of the information provided by subjects with complete data and partially complete data. Most software packages for LCA employ a FIML approach because it requires no additional input from the user other than specifying that what code is used to denote missing data. However, this approach cannot handle missing data when missingness occurs in group variable or covariates in multiple-group LCA.</p>
<p>The package  estimates model parameters using a FIML approach when some responses are found missing on manifest items: in E-step the missing responses are excluded from computing the posterior probability; and in M-step the indicator <span class="math inline">\(I(y_{igm} = k)\)</span> for the missing response is replaced with the updated <span class="math inline">\(\rho\)</span>-parameter from previous iteration. In short, the package  can handle any ignorable missing data on manifest items, but individuals with missing data on group variable or any covariate are deleted from the analysis.  the package  can handle any ignorable missing data on manifest items, but individuals with missing data on group variable or any covariate are deleted from the analysis. However, missing values on group variable and covariates can be treated using multiple multivariate imputation by chained equations (MICE, ), which is implemented in the R package ~. MICE imputation could be used to create multiple sets of complete group variable and covariates for multiple-group LCA. Each complete dataset can be analyzed using the package  and combining results across imputed datasets are easily obtained.</p>
</div>
<div id="finding-global-maximum" class="section level2">
<h2>Finding global maximum</h2>
<p></p>
<p>Since the log-likelihood of LCA may have several local-maxima problem, the estimated parameters from EM algorithm can be deviated from the globally optimal solution. To cope with this problem, we recommend starting the algorithm using several different initial sets of random values and ascertaining whether they consistently converge to the same solution. If they converge, the solution can be considered as the ML estimates. If not, we recommend examining the distribution of the likelihood values and selecting the largest likelihood value, which usually corresponds to the ML solution. The package  allows investigators to try different starting values either by using random starting values or providing their own starting values. An investigator can select the number of initial sets of random values (default is 10) in the package , and then the package iterates EM algorithm a small number of times (default is 50) for each set of random values. Among the initial sets of model parameters, those producing the largest value of likelihood will be chosen for the main iteration.</p>
</div>
<div id="standard-error-calculation" class="section level2">
<h2>Standard error calculation</h2>
<p></p>
<p>The standard error of the estimated parameters can be calculated using the observed empirical information matrix ,</p>
<p><span class="math display">\[
\boldsymbol{I}_{e}(\hat{\boldsymbol{\Psi}};\mathbf{Y}) = 
\sum_{g = 1}^{G}\mathbf{s}(\mathbf{Y}_{g}; \hat{\boldsymbol{\Psi}})\mathbf{s}^\top(\mathbf{Y}_{g}; \hat{\boldsymbol{\Psi}}),
\]</span></p>
<p>where <span class="math inline">\(\mathbf{s}(\mathbf{Y}_{g}; \hat{\boldsymbol{\Psi}})\)</span> is the score function of the parameter vector <span class="math inline">\(\boldsymbol{\Psi}\)</span> for the <span class="math inline">\(g\)</span>th group, evaluated at their MLE <span class="math inline">\(\hat{\boldsymbol{\Psi}}\)</span>. In the parameter vector <span class="math inline">\(\boldsymbol{\Psi}\)</span>, all probability parameters such as <span class="math inline">\(\delta\)</span> and <span class="math inline">\(\rho\)</span>-parameters are transformed into free parameters using baseline logit function. The variance of <span class="math inline">\(\hat{\boldsymbol{\Psi}}\)</span> can be obtained by the inverse of <span class="math inline">\(\boldsymbol{I}_{e}(\hat{\boldsymbol{\Psi}};\mathbf{Y})\)</span>. However, as our target parameters are a re-parameterized version of <span class="math inline">\(\boldsymbol{\Psi}\)</span>, we should apply delta method to the variance of <span class="math inline">\(\hat{\boldsymbol{\Psi}}\)</span>. Let <span class="math inline">\(q(\boldsymbol{\Psi})\)</span> denote the original parameters of multiple-group latent class models. Then, the variance-covariance matrix of the estimates is</p>
<p><span class="math display">\[
\textsf{Var}\left(q(\hat{\boldsymbol{\Psi}})\right) =
J_q(\hat{\boldsymbol{\Psi}})\textsf{Var}(\hat{\boldsymbol{\Psi}})J_q(\hat{\boldsymbol{\Psi}})^\top,
\]</span></p>
<p>where <span class="math inline">\(J_q(\hat{\boldsymbol{\Psi}})\)</span> is the Jacobian matrix of the function <span class="math inline">\(q()\)</span> evaluated at the MLE of <span class="math inline">\(\boldsymbol{\Psi}\)</span>. Details of the score functions and the Jacobian matrices are provided in Appendix.</p>
</div>
<div id="assessing-absolute-model-fit-for-measuring-goodness-of-fit" class="section level2">
<h2>Assessing absolute model fit for measuring goodness-of-fit</h2>
<p></p>
<p>Absolute model fit refers to whether a specified multiple-group latent class model provides an adequate representation of the data. Typically, the analyst assesses absolute model fit by fitting a particular model to the observed data and testing the null hypothesis that the observed data has been produced by the fitted model. Thus, one usually hopes to find a model for which the null hypothesis is not rejected. This hypothesis test for LCA is based on a contingency table; the expected cell counts are estimated according to the specified model and its estimated parameters, then compared to the observed cell counts. The likelihood-ratio statistic, <span class="math inline">\(G^2\)</span>~ is used to assess absolute model fit in the package . The <span class="math inline">\(G^2\)</span> test statistic is derived from the difference in the log-likelihood values between the fitted model and the saturated model (i.e., expected and observed cell counts, respectively), where the residual degree of freedom is calculated by subtracting the number of parameters in the fitted model from those in the saturated model. The number of parameters for the saturated model is the lesser of number of possible combinations of categorical variables and number of cases in the model.</p>
<p>It should be noted that the contingency table for the LCA type of model is commonly sparse. When there are many cells containing very few observations in the cross-classification table, the large-sample approximation to the chi-square distribution for the <span class="math inline">\(G^2\)</span> statistic is not appropriate. In such case, the package  allows us to conduct goodness-of-fit test using the bootstrap likelihood-ratio test (BLRT) statistic~. This approach generates random datasets multiple times using the estimated parameters and calculates the <span class="math inline">\(G^2\)</span> statistic for each generated dataset. In BLRT the resulting distribution of the <span class="math inline">\(G^2\)</span> statistic across the random datasets is used as the reference distribution. The relative position of the <span class="math inline">\(G^2\)</span> statistic obtained from the original dataset within the reference distribution can be used as a measure of absolute model fit. In fact, the right tail probability of the observed <span class="math inline">\(G^2\)</span> value is regarded as a bootstrap <span class="math inline">\(p\)</span>-value. For example, if the observed <span class="math inline">\(G^2\)</span> value falls in the uppermost tail of the reference distribution, we may conclude that this test statistic is unlikely observed under the model corresponding to the null hypothesis. Such finding would provide evidence to reject the null hypothesis.</p>
</div>
<div id="assessing-relative-model-fit-for-exploring-group-differences" class="section level2">
<h2>Assessing relative model fit for exploring group differences</h2>
<p></p>
<p>When comparing two or more groups in multiple-group latent class model, it should be checked if the latent features are identical or not across groups. The relative model fit refers to deciding which of two or more models represents a better fit to a particular dataset. The measurement invariance in multiple-group LCA can be tested by comparing the model fits of constrained versus unconstrained model; the unconstrained (full) model allows all parameters to vary across groups, while the constrained (reduced) model allows only the class prevalences to vary but item-response probabilities to be equal across groups. The package  conducts the chi-square likelihood-ratio test (LRT) to assess relative model fit by comparing two competing models for testing measurement invariance.</p>
<p>Similar to the item-response probabilities, the coefficients for the level-1 covariates can also be tested for equality across groups using chi-square LRT in the package . By comparing the fit of reduced model with the coefficients held constant across groups (i.e., <span class="math inline">\(\boldsymbol{\beta}_{c} = \boldsymbol{\beta}_{c \mid 1}= \cdots = \boldsymbol{\beta}_{c \mid G}\)</span> in mgLCR and <span class="math inline">\(\boldsymbol{\beta}_{1c} = \boldsymbol{\beta}_{1c \mid 1} = \cdots = \boldsymbol{\beta}_{1c \mid W}\)</span> in npLCR for <span class="math inline">\(c=1,\ldots,C\)</span>) against full model with freely varying coefficients, we obtain evidence on whether the effects of level-1 covariates on latent class prevalences can be assumed to be identical across groups. To make the group comparison for coefficients valid, the assumption of measurement invariance must be met to ensure consistent meaning of latent classes across groups.</p>
<p>The deviance statistic, a test statistic of LRT for relative model fit, is obtained by twice the difference in the log-likelihood values of two competing models. The degree of freedom for deviance statistic is the difference in the number of free parameters of the two multiple-group latent class models. For example, the validity of the measurement invariance assumption can be tested by calculating the log-likelihood from the model where item-response probabilities are constrained to be equal across subgroups and comparing it with the log-likelihood from the freely estimated model.</p>
</div>
<div id="choosing-the-numbers-of-latent-classes-and-latent-clusters" class="section level2">
<h2>Choosing the numbers of latent classes and latent clusters</h2>
<p></p>
<p>The chi-square LRT cannot be used to compare latent class models with a different number of latent classes or clusters because these two models are not nested. Thus, the package  provides several information criteria commonly used in LCA such as Akaike’s information criterion (AIC), Bozdogan’s criterion (CAIC), and Schwartz’s Bayesian information criterion (BIC)  to compare the fit of non-nested competing models; the model with a smaller AIC (or BIC) value is preferred. Another model fit index provided by the package is entropy, which is widely used in research practices although it can be a poor measure for model selection as it often depends on the number of classes . The model with relatively higher entropy value is preferred.</p>
<p>The package  also generates the empirical distribution of the deviance statistic to help select a better model between two non-nested competing models with a different number of latent classes or clusters using BLRT . The null hypothesis is the simpler model is adequate. Thus, the bootstrap sample will be drawn from the simpler model. Using a generated bootstrap sample, both competing models are estimated and the deviance between these two models is calculated. By repeating this procedure multiple times, we can construct the reference distribution of the deviance. Similar to the bootstrap <span class="math inline">\(p\)</span>-value for the <span class="math inline">\(G^2\)</span> statistic, the relative position of observed deviance within the reference distribution presents bootstrap <span class="math inline">\(p\)</span>-value; the null model with a bootstrap <span class="math inline">\(p\)</span>-value &gt; 0.05 is preferred with a significance level of <span class="math inline">\(\alpha = 0.05\)</span>. An important advantage of using BLRT is that this method can be applied to the test for comparing two nested latent class models even when the condition for large-sample approximation is not satisfied. It should be noted that the optimal model should be selected by comprehensively considering both conceptual and analytical implications, and the quantitative goodness-of-fit statistics.</p>
</div>



<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
